{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f067f640",
   "metadata": {},
   "source": [
    "Ollama : LLM inference server runing at background\n",
    "Qdrant : vector database server running at background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232a7df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tushar/work/LLM/RAG/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8854beb5",
   "metadata": {},
   "source": [
    "Qdrant Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37267c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadrant server docker is running at localhost:6333\n",
    "qdrant = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6537474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION = \"docs\"\n",
    "# Create collection if not exists\n",
    "if COLLECTION not in [c.name for c in qdrant.get_collections().collections]:\n",
    "    qdrant.create_collection(\n",
    "        collection_name=COLLECTION,\n",
    "        vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13380874",
   "metadata": {},
   "source": [
    "Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "348222d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedder = SentenceTransformer(EMBED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9008d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Store Sample Docs ----\n",
    "docs = [\n",
    "    \"Qdrant is a vector database used for semantic search.\",\n",
    "    \"Ollama allows running local LLMs like Llama3 or Mistral.\",\n",
    "    \"Vector search enables retrieval augmented generation (RAG).\"\n",
    "]\n",
    "\n",
    "vectors = embedder.encode(docs).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64356e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "for i in range(len(docs)):\n",
    "    points.append(PointStruct(id=i, vector=vectors[i], payload={\"text\": docs[i]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e91e9c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant.upsert(collection_name=COLLECTION, points=points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38ffb7e",
   "metadata": {},
   "source": [
    "---- Query + Retrieval ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "319d93c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Qdrant used for?\"\n",
    "query_vec = embedder.encode(query).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "779c0e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19029/2484428178.py:1: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = qdrant.search(\n"
     ]
    }
   ],
   "source": [
    "search_results = qdrant.search(\n",
    "    collection_name=COLLECTION,\n",
    "    query_vector=query_vec,\n",
    "    limit=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cdd1300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=0, version=0, score=0.5962877, payload={'text': 'Qdrant is a vector database used for semantic search.'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=2, version=0, score=0.153411, payload={'text': 'Vector search enables retrieval augmented generation (RAG).'}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f18e1e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\".join([r.payload[\"text\"] for r in search_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8defe3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Qdrant is a vector database used for semantic search.\\nVector search enables retrieval augmented generation (RAG).'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33970de3",
   "metadata": {},
   "source": [
    " ---- Ask Ollama with Context ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "653bfd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Ask Ollama with Context ----\n",
    "prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "response = ollama.generate(model=\"llama3\", prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98dc036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the context, Qdrant is a vector database used for **semantic search**, which enables **Retrieval Augmented Generation (RAG)**. In other words, Qdrant is used for searching and generating content based on semantic similarity between vectors.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"response\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

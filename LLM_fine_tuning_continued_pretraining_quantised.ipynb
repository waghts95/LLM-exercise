{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFMc92dpN4G4"
   },
   "source": [
    "This is low memory training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAxzv_OovPD6"
   },
   "source": [
    "üß± 1Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C3q5QNYctWSQ",
    "outputId": "1db62cac-bdb3-48c3-9afb-fa69c6ae6ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets accelerate bitsandbytes peft sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QItwdrb8vaVy"
   },
   "source": [
    "üß† 2Ô∏è‚É£ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2EL6kTv7vZnO"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGWqZ8sb67FJ"
   },
   "source": [
    "üß© 3Ô∏è‚É£ Inspect and Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "900b4366e7b3485d9f5f6f5b34a48385",
      "78f6ea6fca7b4f48af3964dc58a4bd9d",
      "a8121390f11740aeb6ac89c770a290df",
      "178887ac16bc4ec3adb2de6e2b314a4c",
      "97570ff4a7814c9594f139d1836cc29f",
      "c36378e7e70b4cd482954aece95282b9",
      "a0a95d223b394efb9ce7efc77725847c",
      "10d9251f653e4f84a698b42cc29cd7ea",
      "075d43f75317412eb4e6c71b07ee885e",
      "a4fd8fe24d4746db871068fd6702fefb",
      "9846068fc78f4a4aa4e4f9a6e7f80b2b"
     ]
    },
    "id": "baR0CGjp8n6-",
    "outputId": "641ba1a6-b127-4914-bf4f-a5d9f38a41ac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900b4366e7b3485d9f5f6f5b34a48385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Context', 'Response'],\n",
      "        num_rows: 3512\n",
      "    })\n",
      "})\n",
      "{'Context': \"I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?\", 'Response': \"If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media. \\xa0Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living. \\xa0They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible. \\xa0 Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\"}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load your uploaded JSON file directly\n",
    "dataset = load_dataset(\"json\", data_files=\"/content/combined_dataset.json\")\n",
    "\n",
    "# View sample\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfdhBgfj8y_E"
   },
   "source": [
    "üß© Prepare for Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IM8RYFrI858Y"
   },
   "source": [
    "Combine context and response into one conversational string so the model learns counselor-style replies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c58f045ced7443abbd1799d1179a4aec",
      "f52cd766a9ed4751af32ac28460d72f4",
      "77d5c424032f4bf396a81aea9fefc026",
      "785f065fd5bf4ea2aa7fb15b58e53a86",
      "b642d65875f74ca8869eef9c2c3b430a",
      "e89f2ca47dcb49e3942fde9bc98f1d5a",
      "fda85b2a0f854ddfbee3bcbdd11f11fd",
      "c52acc563f9046e5922e81b9a5fc4e8f",
      "18690b76fdcd48d48838865f318d5ea8",
      "c8e0a001db124a3799c681351fd49ee9",
      "9446536cada94e0db86ebb0b447eb67f"
     ]
    },
    "id": "ytQFIiFy82P6",
    "outputId": "a490815b-da72-488a-f0c8-dce9027906aa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58f045ced7443abbd1799d1179a4aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_conversation(example):\n",
    "    return {\n",
    "        \"text\": f\"Client: {example['Context'].strip()}\\nCounselor: {example['Response'].strip()}\"\n",
    "    }\n",
    "\n",
    "dataset = dataset[\"train\"].map(format_conversation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxdDDSXjwJ90"
   },
   "source": [
    "ü¶ô 6Ô∏è‚É£ Choose Base Llama Model\n",
    "\n",
    "You can choose any open-source variant:\n",
    "\n",
    "    Model\t                         Parameter\t   Notes<br>\n",
    "    \"meta-llama/Meta-Llama-3-8B\"\t  8B\t      Best balance of quality/performance\n",
    "    \"meta-llama/Llama-2-7b-hf\"\t      7B\t      Older but lightweight\n",
    "    \"meta-llama/Meta-Llama-3-70B\"\t  70B\t      For multi-GPU clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MFUUfbswqtR"
   },
   "source": [
    "For Colab, stick with the 8B or 7B versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_q60gKszjuz"
   },
   "source": [
    "‚öôÔ∏è 8Ô∏è‚É£ Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401,
     "referenced_widgets": [
      "675e69a1456e414bb98a2e1b9e019f88",
      "44d5753da82f4e519ca6c63505890d3e",
      "ae2b0f90320a4bd69f07a991b1b12aae",
      "2041ed7e4c9d42c085698a96fe8352e1",
      "d957ac6b6d13472bb3b6a7eefd163ded",
      "5d75ed57ba4547c3b616ad6b1787b26f",
      "065cde6b6568468ebec4d396c49a346e",
      "625720a301134bd88c405b8ecb3b05a7",
      "9f4eb07c3d8545b4bc6d785a9aad95a5",
      "5038dc7aa69d4aed99efa1f09a157ca1",
      "c9e1df4e74b746d1bfefa6a31b5198a8",
      "6a2a6cdfae1143e3a5350bc58a44d364",
      "b978cdfa3f4f42d8a6a3b498363a57cb",
      "2bcc633a02794a28998801beb8484aca",
      "37a4ad3c6b4a4334ba04b8f48924ea17",
      "8bab348c9c7e4d108704af97a09ed78f",
      "f1d4574e060f4953afd9a70d6c06e649",
      "4cab77e9157b4b759de8c63cb0c727bb",
      "4297314214a64ae5b2e33bf154472a2d",
      "1429f31770544d7c936fa7646e7ad84b",
      "5acd17a8cc064d1bbcba84a9d236601d",
      "6873eaccff4445d3aa431b302a8f0431",
      "21a2a8a8fee2463b9d304945905d6017",
      "1de4f89821144a74b9b6478e2a797659",
      "8965a665f14241709fcdde3bb202fc76",
      "3608ef145cf540b8b8a698f6237b39ec",
      "3c597546491b4ce4a1025f13d7659c4f",
      "1e4ad6c0d08c49509db8f45106185998",
      "a7779ad16602453d846596cb1e861e71",
      "c35fa6fc14ea43b7b1c5bfaac0946216",
      "984d65afc28e41b3a601cfc2f8b488c0",
      "2a459691aa164710ab35911d6aa670fc",
      "016c8c99fc0a47178f095bc93382a892",
      "eaaf84f9ad714ef1a6f8f80667d76c40",
      "9b606f7f75244419b4ec9ea015cc5648",
      "fa71c20ae7f54a6fac170615105b677d",
      "821ba891f22c494c950e9c8651bffbdd",
      "95bc4daf99ea400e957c81fb7768f5a6",
      "249c83771c9b45d6a8d35fbebd91cd87",
      "d0bc5db089db4007b0a261e08f4b7178",
      "153eb8f2cbc34c2f916d2c0402680d8e",
      "a5901382e26b4fa68eceec08a52c61f7",
      "4ac487c3b15d4d0ca214339d3f7295b7",
      "f89a2918e39041268752852f8c9c8a56",
      "7cc9cf5e56094acb8df058e392b8e555",
      "ca0ea2f9b45a466e9ca58cca441c5f16",
      "0a7f64acce7c4fe4bbb3916fe1dc4006",
      "a4064b1a22494dff9d8344e037844fc2",
      "128c280a76354fb59448357c41b764d4",
      "3e44f8f14e2e4f4bb6d448aea97a990e",
      "873b5621f31d49f3b883c73f0dc0ced7",
      "501739f37a7b4d06a085510b7a5c50a4",
      "35a27d61082c4dedbeaf4d1b0cf621af",
      "a635924d9831414f8d428aa59132a033",
      "94df6383296e4459accc3403282df487",
      "6a3ee1c058a14de5846e0cbb21eef1a3",
      "737d2b7fc3464d2b85e02b40e06e311d",
      "5d92782bd5c64ef9bcad7a5b28f0ac5e",
      "66c91e8c87b54790a04a2143c586f91d",
      "f46810ff2194420a8808ff4256524f8c",
      "d25daa6a733d4f228b7afbcb6f12cad9",
      "343f74fe759f4ccca2e7661e644cb0a1",
      "5dc7dee8374c4531a4bd21a88a65dcb1",
      "7074f14dcce14d3b9becd7874266d2ca",
      "f6f619f61df64429ac386dd9688f42ba",
      "f5bcead9018b4ea3aa341b8a4be88b57",
      "2bc5a0304e3b47bebd54472d95bc7dec",
      "edb09401b38348b98b14a9b989dd6517",
      "fbb60a9fb52445bcbee8eecc98c6e8e0",
      "09e93ffea22545b193bdce30b57e0ff6",
      "d3d72df8334641589ff5e2ef642e3756",
      "d87b1ecaf63b4e65880e99765332550c",
      "34710298f1bc49138f408d86c57bba49",
      "1f77d6d3b4364fb9930fda3862e4f4a4",
      "56c20d19904f40658702fd8cf0ad3250",
      "b36ceba4b7c94754bd9199ed2c7d069c",
      "98e258759ec7416fad7c9cdc058dc6a0",
      "ca496a2965fb4069bbe3bc9d3b061667",
      "62d3466a9ead411294298d4348345e96",
      "0cd73cab8d234a8d9419c17a0fad69ef",
      "4b20f8eed2f749c9ba013d6b5f4ed82b",
      "c3d31a12abf645aab7edac846edf7283",
      "4f0aa394101e407989cd8223b23b2caf",
      "abe23ff5247b4930a11979792d030a51",
      "42bf5191a93140d3b408aa6040d8b13d",
      "8dcb2d3bbab8492eaaf87e4466d5ad35",
      "bb9fda24bd1f4c25a828de4271111d46",
      "9379bb2794144b54b3416a3309ea6493",
      "1d385b8c45c542c6ab5ce7475f5730ee",
      "c2ff826336264307afe916395b0acda9",
      "76fb8fd9f0674cbc8b20e927c8a51876",
      "40fd9271dfab43f7b6500eba085c16d3",
      "6076964c8bb54dd8970bb1d91a1e459f",
      "a992e458c53e403cb4ef133a92c1ab9d",
      "aca32d69b4034cff98c5201a385799cb",
      "102391092b7c4117bb687041a5265516",
      "099e29e337b2479baad7ebffca880ab5",
      "1c68b779fa0440caa702e50c422818b9",
      "336dedde1b4f42c5be1d9540465ce448",
      "8109127d4e3c48de8610215d44587e29",
      "cf217478ed4a4638994036e17367bd2d",
      "1209acaf1df4438ebebe5f82bc84db8e",
      "48b7237be9d94a68b828a8f99fa89b3a",
      "2e7d1e178c4f4cad92ded2dbe0bc788f",
      "5e1abbe256354f2f97626b576925de3d",
      "3a213f5e38e441a6a9b38ad2b954fdfc",
      "7ba8d2ab540f4d5ba3065463705cb817",
      "6607e243617e4ccdb52782b33a072e22",
      "67e3688553b243838df249553ad86df8",
      "6cf61bd57ae64166adb2141c3811211a",
      "f10d1416dff84af48372274f6d5a4991",
      "836cf3d66882407daba14cb259d9134d",
      "55cbc942bbf14d9aa91c0f5441e89a80",
      "55d4c55a342745caa36a6b24d26abd15",
      "e846fbf3691140109e3f73429e469d52",
      "8edcc3097c204f2086c14e1e43adcdae",
      "5b892c1eb16b43ba99ee120d1645701c",
      "9233a5127fde493da0f5f326df69e5e4",
      "a0a2f28897184877b15ae6ef4bac8a3b",
      "0854829a63e849a39cc01a0ef534c5bc",
      "01c2f72b82ac4389ac84e3049b779699",
      "1ac54a86d4b64b7db7a93018f0027cf3",
      "d1aeff8919a04121bf4b344a81561f5a",
      "d8fb3fca70c7413ca2ebea40f92fd343",
      "26fd0697f8014e7e962e573c767a78ac",
      "cdedbd3f038e4b8086198a0deebc7570",
      "812ca79b28f64ff2824a9f6463554083",
      "9bb4ece64978463ba800d1e381aca97f",
      "03c67fe2d48e4866acb7535017690998",
      "94c8d0a9e6a146f8b95d3bbbcf734b61",
      "49f04e12cabe4fc29d329db052e559ec",
      "8e9956f660ef43709956b6d4f8283fa9"
     ]
    },
    "id": "AjDvIwxowlvz",
    "outputId": "c7d3a3b9-bd6d-4ceb-ce65-f3c3109a125c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675e69a1456e414bb98a2e1b9e019f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2a6cdfae1143e3a5350bc58a44d364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a2a8a8fee2463b9d304945905d6017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaaf84f9ad714ef1a6f8f80667d76c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc9cf5e56094acb8df058e392b8e555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3ee1c058a14de5846e0cbb21eef1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc5a0304e3b47bebd54472d95bc7dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca496a2965fb4069bbe3bc9d3b061667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d385b8c45c542c6ab5ce7475f5730ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8109127d4e3c48de8610215d44587e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10d1416dff84af48372274f6d5a4991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac54a86d4b64b7db7a93018f0027cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_name = \"NousResearch/Llama-2-7b-chat-hf\" # Changed to a publicly available model\n",
    "\n",
    "# 4-bit quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Llama has no pad_token by default\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config, # Apply quantization config\n",
    "    device_map=\"auto\",\n",
    "    # torch_dtype=torch.float16, # Data type is handled by BitsAndBytesConfig\n",
    ")\n",
    "\n",
    "# Prepare model for QLoRA fine-tuning\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# LoRA config for low-rank adapters\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gI9lz1Cyzeoj"
   },
   "source": [
    "üßæ 7Ô∏è‚É£ Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtw0_gLxzgt7"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=1024)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBk_2xbn-y0f"
   },
   "source": [
    "‚öôÔ∏è Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9-u4hDdMzku4"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eNhb3s2ztnn"
   },
   "source": [
    "üöÄ üîü üßÆ Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uvACDsOfztAo"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama3_counseling_domain\",\n",
    "    per_device_train_batch_size=1,  # Reduced batch size\n",
    "    gradient_accumulation_steps=32, # Further increased gradient accumulation steps\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=2,\n",
    "    fp16=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    gradient_checkpointing=True, # Enabled gradient checkpointing\n",
    "    optim=\"adamw_torch\", # Specify AdamW optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lv8uurREzyKz"
   },
   "source": [
    "üöÄ 7Ô∏è‚É£ Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "QzoA0-aIz6Xb",
    "outputId": "93cbbfd6-cc51-44e5-a72f-8ce5227741bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/220 1:38:04 < 2:00:05, 0.02 it/s, Epoch 0.90/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.447100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkIH5Wk5-kbC"
   },
   "source": [
    "üíæ 8Ô∏è‚É£ Save the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TGbgP9CM-lT7"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"./llama3_counseling_domain\")\n",
    "tokenizer.save_pretrained(\"./llama3_counseling_domain\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UIXRTCm-pSx"
   },
   "source": [
    "üß™ 9Ô∏è‚É£ Test Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOEl76jm-nzT"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"./llama3_counseling_domain\", tokenizer=tokenizer)\n",
    "\n",
    "prompt = \"Client: I feel anxious and worthless lately. What should I do?\\nCounselor:\"\n",
    "print(pipe(prompt, max_new_tokens=100)[0][\"generated_text\"])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
